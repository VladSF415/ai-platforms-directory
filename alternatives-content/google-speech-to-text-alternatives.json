{
  "slug": "google-speech-to-text-alternatives",
  "platformSlug": "google-speech-to-text",
  "title": "Best Google Speech-to-Text Alternatives in 2025: Top 10 Tools Compared",
  "metaDescription": "Explore the top Google Speech-to-Text alternatives for 2025. Compare features, pricing, and accuracy of leading tools like OpenAI Whisper, AssemblyAI, and Otter.ai for your transcription needs.",
  "introduction": "Google Speech-to-Text has long been a dominant force in the automated transcription and speech recognition landscape, offering robust accuracy and deep integration with the Google Cloud ecosystem. However, as the AI audio market rapidly evolves, developers, businesses, and researchers are increasingly seeking alternatives. This search is driven by several key factors: the need for more transparent or flexible pricing models, a desire for specialized features beyond general transcription, requirements for on-premise or open-source deployment, and the pursuit of tools better aligned with specific use cases like meeting analysis, music processing, or advanced speaker diarization.\n\nWhile Google's service excels with its massive language support and the power of the Chirp foundation model, its cloud-first, API-centric approach isn't a perfect fit for every scenario. Some users find the pricing structure complex for variable workloads, others require more granular control over the underlying models, and many seek platforms that bundle transcription with adjacent capabilities like sentiment analysis, automated summaries, or seamless team collaboration. The rise of powerful open-source models has also democratized access to state-of-the-art speech recognition, enabling customization and offline use that cloud APIs cannot provide.\n\nThis guide provides a comprehensive analysis of the top alternatives to Google Speech-to-Text. We've evaluated tools across the spectrum—from enterprise-grade APIs and specialized meeting assistants to open-source libraries for developers and cutting-edge creative audio AI. Whether you're building a scalable application, analyzing team meetings, conducting audio research, or generating synthetic media, understanding these alternatives is crucial for selecting the optimal tool that balances cost, capability, and integration ease for your specific project in 2025.",
  "mainPlatformAnalysis": {
    "overview": "Google Speech-to-Text is a cloud-based AI service that converts audio to text using Google's state-of-the-art Chirp foundation model. It enables developers and businesses to add accurate speech recognition to applications, supporting real-time streaming, batch processing, and custom model adaptation. Its key differentiators are industry-leading accuracy powered by Google's deep research, support for over 125 languages and variants, and seamless integration within the Google Cloud ecosystem.",
    "limitations": [
      "Complex, usage-based pricing that can be unpredictable for high-volume applications",
      "Primarily an API service with less focus on end-user applications or collaborative features",
      "Vendor lock-in to the Google Cloud platform, with limited offline capabilities"
    ],
    "pricing": "Google Speech-to-Text operates on a pay-as-you-go model. Pricing varies by audio type and features: Standard audio transcription costs $0.006 per 15 seconds, while video audio is $0.012 per 15 seconds. Enhanced models for specific domains (like phone call or video) cost more, and additional features like speaker diarization and multi-channel recognition incur extra charges. Custom model training also has separate costs. Volume discounts are available.",
    "bestFor": "Enterprises and developers already embedded in the Google Cloud ecosystem who need highly accurate, scalable, multilingual transcription via API and can manage variable, usage-based costs."
  },
  "alternatives": [
    {
      "name": "OpenAI Whisper",
      "slug": "openai-whisper",
      "rank": 1,
      "tagline": "The powerful, free, and open-source transcription engine.",
      "description": "OpenAI Whisper is an open-source automatic speech recognition (ASR) system that transcribes and translates speech from audio across dozens of languages. Trained on a massive and diverse 680,000-hour dataset, it is designed to be robust to accents, background noise, and technical language, making it highly versatile for general-purpose use. Its unique value lies in being a state-of-the-art model that is freely available for both research and commercial use, offering unparalleled flexibility for deployment, customization, and offline processing.",
      "pricing": "Open-source (free)",
      "bestFor": "Developers, researchers, and cost-conscious businesses needing a highly capable, customizable, and free transcription model for integration into their own applications or for offline use.",
      "keyFeatures": [
        "Multilingual transcription and translation",
        "Robust to noise and accents",
        "Multiple model sizes for speed/accuracy trade-off",
        "Open-source and freely available for commercial use"
      ],
      "pros": [
        "Completely free with no API costs",
        "Can be run locally for data privacy",
        "Highly customizable and extensible",
        "Strong all-around accuracy"
      ],
      "cons": [
        "Requires technical expertise to deploy and manage",
        "No managed API or direct support",
        "Real-time streaming requires custom implementation"
      ],
      "whySwitch": "Choose Whisper over Google Speech-to-Text if you need a free, open-source solution for offline deployment, complete control over your data pipeline, or to avoid recurring API costs and vendor lock-in."
    },
    {
      "name": "AssemblyAI",
      "slug": "elevenlabs-voice-cloning-v2",
      "rank": 2,
      "tagline": "The developer-friendly API for speech-to-text and audio intelligence.",
      "description": "AssemblyAI is a leading API platform for converting speech to text and extracting insights from audio and video data. It provides production-ready, high-accuracy models for core transcription, speaker diarization, and advanced NLP tasks like sentiment analysis, entity detection, and content moderation. It uniquely targets developers and enterprises with a simple API, fast processing, and a focus on building scalable, real-world AI applications for audio, making it a strong contender for those who need more than just raw transcription.",
      "pricing": "Freemium model. Free tier includes 5 hours of transcription per month. Paid plans start at $0.00025 per second ($0.90/hour) for the Core Transcription model, with volume discounts available.",
      "bestFor": "Developers and product teams building applications that require not just transcription, but also deeper audio understanding (sentiment, topics, entities) via a clean, well-documented API.",
      "keyFeatures": [
        "High-accuracy transcription API",
        "Real-time streaming and async processing",
        "Audio Intelligence models (sentiment, entities, PII redaction)",
        "Speaker diarization and summarization"
      ],
      "pros": [
        "Simple, predictable pricing per hour of audio",
        "Excellent developer experience and documentation",
        "Powerful suite of audio intelligence features",
        "Fast processing times"
      ],
      "cons": [
        "Language support is less extensive than Google's",
        "Advanced features require separate API calls/costs",
        "Primarily an API, not an end-user tool"
      ],
      "whySwitch": "Switch to AssemblyAI for a more developer-centric API experience, clearer and often more predictable pricing for audio intelligence features, and a strong focus on extracting actionable insights from transcripts."
    },
    {
      "name": "Otter.ai",
      "slug": "assemblyai",
      "rank": 3,
      "tagline": "Your AI-powered meeting assistant for teams.",
      "description": "Otter.ai is an AI-powered meeting assistant that provides real-time transcription, automated summaries, and action item extraction for conversations. Its key capabilities include speaker identification, collaborative note-taking, and integration with popular calendar and conferencing platforms like Zoom and Google Meet. It uniquely combines high-accuracy transcription with collaborative features, making it a central hub for meeting notes, primarily targeting professionals, students, and teams who need to capture and share insights from discussions.",
      "pricing": "Freemium. Basic free plan offers 300 monthly transcription minutes. Pro plan starts at $10/user/month for 1,200 minutes. Business and Enterprise plans offer more features and volume.",
      "bestFor": "Teams, professionals, and students who need a dedicated tool for transcribing, summarizing, and collaborating on meeting notes and conversations.",
      "keyFeatures": [
        "Real-time meeting transcription",
        "Speaker identification and diarization",
        "Automated summaries and action item extraction",
        "Integration with Zoom, Teams, Google Meet"
      ],
      "pros": [
        "Excellent for collaborative meeting notes",
        "User-friendly interface for non-technical users",
        "Strong integration with conferencing tools",
        "Useful features like summary and action items"
      ],
      "cons": [
        "Less suited for bulk file processing or API-driven app development",
        "Pricing is per user, not per audio hour",
        "Limited customization compared to raw APIs"
      ],
      "whySwitch": "Choose Otter.ai over Google Speech-to-Text if your primary need is transcribing and managing meetings with a team, and you value collaboration features, summaries, and direct conferencing app integrations over a raw API."
    },
    {
      "name": "pyannote.audio",
      "slug": "librosa",
      "rank": 4,
      "tagline": "The open-source toolkit for advanced speaker diarization.",
      "description": "pyannote.audio is an open-source Python toolkit built on PyTorch, providing neural building blocks for speaker diarization—the task of segmenting audio by speaker identity. Its key capabilities include robust voice activity detection, speaker change detection, overlapped speech detection, and speaker embedding extraction, enabling researchers and developers to build and benchmark diarization pipelines. What makes it unique is its modular, research-oriented design, offering pre-trained models and a standardized evaluation protocol that has become a benchmark in the academic and industrial audio processing community.",
      "pricing": "Open-source (free)",
      "bestFor": "Researchers, data scientists, and advanced developers who need state-of-the-art, customizable speaker diarization capabilities for their projects, often as part of a larger audio processing pipeline.",
      "keyFeatures": [
        "Modular pipeline for speaker diarization",
        "Pre-trained models for voice activity and overlap detection",
        "Speaker embedding extraction",
        "Benchmarking tools and standard protocols"
      ],
      "pros": [
        "Powerful, research-grade diarization for free",
        "Highly modular and customizable",
        "Strong community and academic backing",
        "Integrates well with other Python ML libraries"
      ],
      "cons": [
        "Steep learning curve, requires ML/PyTorch knowledge",
        "Not a managed service; requires self-hosting",
        "Focused on diarization, not full transcription (often paired with Whisper)"
      ],
      "whySwitch": "Switch to pyannote.audio if your core challenge is accurately identifying 'who spoke when' in complex audio, and you need a cutting-edge, customizable open-source solution that goes beyond Google's more generalized diarization features."
    },
    {
      "name": "torchaudio",
      "slug": "murf-ai",
      "rank": 5,
      "tagline": "The essential audio and speech toolkit for PyTorch.",
      "description": "torchaudio is a domain-specific library for PyTorch dedicated to audio and speech processing. It provides essential building blocks for loading, transforming, and augmenting audio data, and includes popular datasets and pre-trained models to accelerate research and development. Its tight integration with the PyTorch ecosystem enables seamless GPU acceleration and automatic differentiation, making it uniquely suited for building end-to-end, differentiable audio pipelines for custom speech recognition or audio analysis models.",
      "pricing": "Open-source (free)",
      "bestFor": "Machine learning researchers, engineers, and students using PyTorch who are building custom speech or audio models from the ground up and need robust data loading, preprocessing, and augmentation tools.",
      "keyFeatures": [
        "Audio I/O, transformations, and augmentations",
        "Integration with PyTorch tensors and GPUs",
        "Popular audio datasets and pre-trained models",
        "Support for building differentiable pipelines"
      ],
      "pros": [
        "Seamless integration with PyTorch's ML ecosystem",
        "GPU acceleration for audio processing",
        "Essential for training custom ASR/models",
        "Strong foundation for research and experimentation"
      ],
      "cons": [
        "Not a transcription service; it's a low-level library",
        "Requires significant ML expertise to use effectively",
        "No out-of-the-box transcription API"
      ],
      "whySwitch": "Choose torchaudio if you are not looking for a pre-built transcription API, but rather the foundational tools to research, develop, and train your own custom speech recognition or audio processing models within PyTorch."
    },
    {
      "name": "librosa",
      "slug": "otter-ai",
      "rank": 6,
      "tagline": "The fundamental Python library for music and audio analysis.",
      "description": "Librosa is a core Python library for music and audio signal analysis, providing the fundamental building blocks for extracting features like tempo, pitch, and timbre from audio files. It is specifically designed for music information retrieval (MIR) and audio analysis tasks, offering robust implementations of spectral analysis, beat tracking, and chroma feature extraction. Its unique value lies in being a free, research-grade, and de facto standard tool for academics, data scientists, and developers working on audio-based machine learning, distinguishing itself from general-purpose signal processing libraries with its music-specific algorithms and ease of use.",
      "pricing": "Open-source (free)",
      "bestFor": "Researchers, data scientists, and developers focused on music analysis, music information retrieval, or any task requiring detailed acoustic feature extraction (tempo, key, harmonics) rather than speech-to-text.",
      "keyFeatures": [
        "Music and audio feature extraction (MFCC, chroma, tempo)",
        "Beat and onset detection",
        "Time-frequency transformations",
        "Display and visualization utilities"
      ],
      "pros": [
        "Industry standard for music/audio analysis in Python",
        "Excellent documentation and examples",
        "Powerful, well-implemented algorithms",
        "Great for exploratory data analysis of audio"
      ],
      "cons": [
        "Does not perform speech recognition/transcription",
        "Focus is on music, not speech",
        "Requires programming/audio processing knowledge"
      ],
      "whySwitch": "Switch to librosa if your goal is not transcription, but analyzing the musical or acoustic properties of audio (e.g., detecting beats, extracting musical keys, analyzing sound textures), a task for which Google Speech-to-Text is not designed."
    },
    {
      "name": "Murf AI",
      "slug": "pytorch-audio",
      "rank": 7,
      "tagline": "Create studio-quality AI voiceovers from text.",
      "description": "Murf AI is a comprehensive AI voice generation platform that enables users to create professional, studio-quality voiceovers and narrations from text. Its key capabilities include a vast library of 120+ lifelike AI voices across 20+ languages, advanced voice customization tools, and an integrated video/audio editor. It uniquely targets content creators, marketers, educators, and businesses seeking to replace traditional voice actors with scalable, cost-effective, and highly realistic synthetic speech, distinguishing itself with its all-in-one studio for adding voice to videos, podcasts, and presentations.",
      "pricing": "Freemium. Free plan offers 10 minutes of voice generation. Paid plans start at $19/month for 120 minutes of annual generation, with higher tiers offering more voices, longer generation, and commercial rights.",
      "bestFor": "Content creators, marketers, educators, and businesses that need to generate high-quality synthetic voiceovers for videos, presentations, e-learning, and advertisements.",
      "keyFeatures": [
        "Extensive library of realistic AI voices",
        "Voice customization (pitch, speed, emphasis)",
        "Integrated audio/video editor with syncing",
        "Multi-language and accent support"
      ],
      "pros": [
        "High-quality, natural-sounding voice output",
        "All-in-one studio for voiceover creation",
        "Easy to use for non-technical users",
        "Useful for creating scalable audio content"
      ],
      "cons": [
        "It is a Text-to-Speech (TTS) tool, not Speech-to-Text",
        "Cannot transcribe audio",
        "Pricing is based on output minutes, not input"
      ],
      "whySwitch": "Choose Murf AI if you need the opposite function of Google Speech-to-Text: generating human-like speech from text, not transcribing speech to text. It's for content creation, not transcription analysis."
    },
    {
      "name": "ElevenLabs Voice Cloning v2",
      "slug": "suno-ai-v4",
      "rank": 8,
      "tagline": "Advanced voice cloning and emotional speech synthesis.",
      "description": "ElevenLabs Voice Cloning v2 is an advanced voice cloning and synthesis platform with improved emotional control, multilingual support, and professional voice studio features. It allows users to create a digital replica of a voice from a short sample and then generate new speech with that voice, controlling intonation and emotion. It stands out for the realism and expressiveness of its cloned voices, targeting creators, game developers, and businesses for dubbing, character voice creation, and personalized audio content.",
      "pricing": "Freemium. Free tier includes 10,000 characters/month. Paid plans start at $5/month for 30,000 characters, with higher tiers offering more characters, more voice clones, and advanced features.",
      "bestFor": "Creators, developers, and media professionals who need to generate highly realistic, emotionally nuanced synthetic speech using cloned voices for dubbing, gaming, animation, or personalized content.",
      "keyFeatures": [
        "High-fidelity voice cloning from short samples",
        "Fine-grained control over speech emotion and intonation",
        "Multilingual speech synthesis",
        "Voice library and design tools"
      ],
      "pros": [
        "Industry-leading voice cloning quality",
        "Unprecedented emotional control in synthetic speech",
        "Powerful for creative and media projects",
        "Intuitive interface for voice design"
      ],
      "cons": [
        "Specialized for voice synthesis, not recognition/transcription",
        "Ethical considerations around voice cloning",
        "Pricing based on output characters"
      ],
      "whySwitch": "Switch to ElevenLabs if your goal is to synthesize speech (Text-to-Speech) with specific, cloned voices and emotional nuance, not to transcribe existing speech. It serves a complementary, creative purpose."
    },
    {
      "name": "Suno AI v4",
      "slug": "pyannote-audio",
      "rank": 9,
      "tagline": "Generate complete songs from a text prompt.",
      "description": "Suno AI v4 is an advanced music generation AI with improved melody generation, longer song creation (up to 5 minutes), and enhanced genre/style control. It includes new vocal synthesis capabilities. The platform empowers users to generate high-quality, full-length musical compositions—complete with vocals, instruments, and structure—from simple text descriptions. It uniquely focuses on end-to-end song creation, distinguishing itself from tools that only handle speech or isolated audio components.",
      "pricing": "Freemium. Free tier offers limited daily credits. Paid plans (Pro and Premier) offer more credits, faster generation, and commercial usage rights.",
      "bestFor": "Musicians, hobbyists, content creators, and marketers who want to generate original, royalty-free music and songs with vocals for projects, inspiration, or content backing tracks.",
      "keyFeatures": [
        "Text-to-song generation with vocals",
        "Genre and style customization",
        "Extended song length (up to 5 minutes)",
        "Instrumental and lyric generation"
      ],
      "pros": [
        "Creates surprisingly coherent and catchy songs",
        "Generates both music and AI-sung vocals",
        "User-friendly, prompt-based interface",
        "Great for inspiration and content creation"
      ],
      "cons": [
        "Not a speech recognition or transcription tool",
        "Output is creative and may require refinement",
        "Limited control over individual musical elements"
      ],
      "whySwitch": "Choose Suno AI if you need to generate original music and songs, not transcribe spoken audio. It's for creative musical composition, a completely different domain from speech-to-text transcription."
    },
    {
      "name": "Udio AI",
      "slug": "udio-ai",
      "rank": 10,
      "tagline": "Craft full songs and instrumentals with AI.",
      "description": "Udio AI is a next-generation platform that generates high-quality, full-length songs and instrumentals from simple text prompts. It empowers users to create complete musical compositions with vocals, multiple instruments, and professional-grade production in seconds, distinguishing itself with a focus on song structure, lyrical coherence, and a vibrant community for sharing and remixing creations. Its target audience ranges from hobbyists and content creators to professional musicians seeking inspiration and rapid prototyping.",
      "pricing": "Freemium. Free tier offers a limited number of songs per month. Subscription plans provide more generations, higher quality, and commercial licenses.",
      "bestFor": "Songwriters, musicians, and content creators looking for an AI collaborator to generate complete, shareable song ideas, backing tracks, or full musical pieces based on text descriptions.",
      "keyFeatures": [
        "Text-to-full-song generation",
        "Community features for sharing and remixing",
        "Lyric generation and vocal synthesis",
        "Genre-blending and style customization"
      ],
      "pros": [
        "Strong focus on cohesive song structure",
        "Active community for feedback and remixes",
        "High-quality, modern production style",
        "Intuitive and fun to use"
      ],
      "cons": [
        "Specialized for music generation, not audio analysis",
        "Creative output varies",
        "No speech transcription capabilities"
      ],
      "whySwitch": "Opt for Udio AI if your objective is generative music creation, not the analysis or transcription of existing speech audio. It's an alternative for creative audio *generation*, not recognition."
    }
  ],
  "comparisonTable": {
    "criteria": [
      "Pricing",
      "Features",
      "Ease of Use",
      "Support",
      "Integration"
    ],
    "scores": {
      "Google Speech-to-Text": [
        7,
        8,
        8,
        7,
        8
      ],
      "OpenAI Whisper": [
        10,
        7,
        5,
        6,
        7
      ],
      "AssemblyAI": [
        8,
        9,
        9,
        8,
        8
      ],
      "Otter.ai": [
        8,
        8,
        10,
        8,
        9
      ],
      "pyannote.audio": [
        10,
        8,
        4,
        6,
        7
      ],
      "torchaudio": [
        10,
        6,
        5,
        6,
        9
      ],
      "librosa": [
        10,
        7,
        6,
        6,
        8
      ],
      "Murf AI": [
        7,
        8,
        9,
        7,
        7
      ],
      "ElevenLabs Voice Cloning v2": [
        7,
        9,
        9,
        7,
        7
      ],
      "Suno AI v4": [
        7,
        8,
        9,
        7,
        6
      ],
      "Udio AI": [
        7,
        8,
        9,
        7,
        6
      ]
    }
  },
  "howToChoose": {
    "title": "How to Choose the Right Google Speech-to-Text Alternative",
    "factors": [
      {
        "name": "Core Use Case",
        "description": "This is the most critical factor. Are you transcribing meetings (Otter.ai), building an app with an API (AssemblyAI), conducting audio research (librosa, torchaudio), or generating synthetic speech/music (Murf, ElevenLabs, Suno)? The tools are highly specialized, so match the tool's primary function to your need."
      },
      {
        "name": "Technical Expertise & Deployment",
        "description": "Consider your team's skills. Open-source tools like Whisper and pyannote.audio offer power and flexibility but require ML/DevOps knowledge for deployment and maintenance. Managed APIs like AssemblyAI and cloud services like Google offer simplicity and scalability. End-user apps like Otter.ai require no coding."
      },
      {
        "name": "Budget and Pricing Model",
        "description": "Evaluate total cost of ownership. Open-source tools are free but have hidden costs (development, hosting). APIs charge per audio hour or feature (Google, AssemblyAI). User-focused apps charge per seat (Otter.ai). Creative tools charge per output minute/credit (Murf, Suno). Choose a model that aligns with your usage patterns and scale."
      },
      {
        "name": "Data Privacy and Control",
        "description": "If you handle sensitive audio (medical, legal, internal meetings), sending data to a third-party cloud API may be a concern. Open-source models (Whisper) that can be deployed on-premise or in a private VPC offer full data control, though at the cost of greater management overhead."
      }
    ]
  },
  "verdict": "Choosing the best Google Speech-to-Text alternative depends entirely on your specific goals and constraints. There is no single 'winner,' but rather a spectrum of tools optimized for different tasks.\n\nFor developers and businesses seeking a direct, API-based replacement with excellent accuracy and additional intelligence, **AssemblyAI** is our top recommendation. It provides a superior developer experience, clearer pricing, and a powerful suite of audio understanding features that often make it a more focused and cost-effective choice than Google's broader API.\n\nIf your priority is cost control, data privacy, or customization, the open-source powerhouse **OpenAI Whisper** is unbeatable. It delivers state-of-the-art transcription for free, allowing for offline processing and integration into custom pipelines, though it requires technical resources to deploy and manage.\n\nFor teams and professionals whose primary need is capturing and collaborating on meetings, **Otter.ai** is the standout choice. It transcends simple transcription by becoming a collaborative hub for conversation insights, making it far more valuable for that specific use case than a raw API.\n\nResearchers and data scientists working on advanced speaker separation should turn to **pyannote.audio**, while those building custom audio ML models need **torchaudio**. If your project involves analyzing the musical qualities of audio, **librosa** is the essential library.\n\nCrucially, tools like **Murf AI**, **ElevenLabs**, **Suno AI**, and **Udio AI** are not direct alternatives for transcription; they are for generative audio tasks (Text-to-Speech, music creation). They become relevant if your workflow involves both transcribing existing audio *and* generating new audio content.\n\nUltimately, the landscape has moved beyond one-size-fits-all solutions. Evaluate your project's requirements for use case, expertise, budget, and data handling to select the specialized tool that will deliver the greatest efficiency and value.",
  "faqs": [
    {
      "question": "Is OpenAI Whisper better than Google Speech-to-Text?",
      "answer": "It depends on your criteria. For raw accuracy on clean audio, they are competitive, with Google sometimes holding a slight edge in specific domains. However, Whisper is completely free and open-source, allowing for offline use and customization, which Google's cloud API does not. Google offers a managed service with support, real-time streaming APIs, and deeper integration with its ecosystem. Whisper is 'better' for cost, control, and privacy; Google is 'better' for a fully managed, scalable enterprise service with guaranteed uptime and support."
    },
    {
      "question": "What is the cheapest alternative to Google Speech-to-Text?",
      "answer": "The absolute cheapest alternative for production use is **OpenAI Whisper**, as it is free and open-source. The only costs are for the computational resources to run it (e.g., cloud VM or your own hardware). For a managed API service, **AssemblyAI's** pricing per audio hour can be more predictable and often more cost-effective than Google's complex pricing tiers for many workloads, especially when using its core transcription feature."
    },
    {
      "question": "What is the best free alternative to Google Speech-to-Text?",
      "answer": "The best free alternative is **OpenAI Whisper**. It provides near state-of-the-art transcription and translation capabilities across many languages at no licensing cost. It is the most powerful and versatile free tool available. For a free, user-friendly application for meeting transcription, **Otter.ai's** free tier (300 minutes/month) is an excellent choice. For free, research-grade audio analysis libraries, **librosa** and **torchaudio** are indispensable."
    }
  ]
}